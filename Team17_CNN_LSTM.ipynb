{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team17_CNN_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhMfRKgnganMFUUJUY18mS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Whitchurch/CNNTensorflowCode/blob/main/Team17_CNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJCjQ8fSb-M1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab87844-56ff-4f0b-b15e-f6f56baa4d85"
      },
      "source": [
        "!pip install tensorflow-GPU"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-GPU\n",
            "  Downloading tensorflow_gpu-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 458.3 MB 10 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (3.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (0.4.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (1.15.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (3.17.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (1.12)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (1.19.5)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (0.37.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (2.6.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (2.6.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (1.41.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-GPU) (5.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-GPU) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-GPU) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-GPU) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-GPU) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-GPU) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-GPU) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-GPU) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-GPU) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-GPU) (3.3.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-GPU) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-GPU) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-GPU) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-GPU) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-GPU) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-GPU) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-GPU) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-GPU) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-GPU) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-GPU) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-GPU) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow-GPU) (3.6.0)\n",
            "Installing collected packages: tensorflow-GPU\n",
            "Successfully installed tensorflow-GPU-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI8e-OL5rtyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b0872dd-6c26-4d17-efef-a48894903194"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxKbf6z3cT3G"
      },
      "source": [
        "Install Tensorflow on Google Co-lab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zNXb0FNcr7S"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv \n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import CuDNNLSTM # A superior LSTM that uses GPU more optimized for training.\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YCMbF1LslRM"
      },
      "source": [
        "Steps to pre-process and load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q76uho-Lsp47"
      },
      "source": [
        "os.chdir(\"drive/My Drive/Colab Notebooks\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPKqnFBNszh3",
        "outputId": "a784bf28-3248-4d3b-f8e8-b17de08f358a"
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Access_Local_directory.ipynb\n",
            "'Copy of Untitled0.ipynb'\n",
            " ECGsignal2700.csv\n",
            " ECGsignal.csv\n",
            " ECGsignal_n2700.csv\n",
            " ECGsignal_n.csv\n",
            " ECGsignal_nwhite.csv\n",
            " Exercise_1_Cats_vs_Dogs_Question-FINAL.ipynb\n",
            " Exercise_2_Cats_vs_Dogs_using_augmentation_Question-FINAL.ipynb\n",
            " Exercise_3_Horses_vs_humans_using_Transfer_Learning_Question-FINAL.ipynb\n",
            " Exercise_4_Multi_class_classifier_Question-FINAL.ipynb\n",
            " FinalCNN_Beginner.ipynb\n",
            " Team17_CNN_LSTM.ipynb\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            " Untitled2.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_WYmzcttPiG",
        "outputId": "63335601-37e0-4868-acbc-a81c59f853a3"
      },
      "source": [
        "#Read the clean signal\n",
        "with open('ECGsignal2700.csv') as csv_file:\n",
        "  csv_reader = csv.reader(csv_file)\n",
        "\n",
        "  for ECGsignal in csv_reader:\n",
        "    print(ECGsignal)\n",
        "  print(\"Finished reading the file\")\n",
        "\n",
        "#Time to dissect the file read data's anatomy:\n",
        "#Total number of items in the list:\n",
        "len(ECGsignal)\n",
        "\n",
        "#Convert the list to an array \n",
        "ECGsignal_arr = np.array(ECGsignal,dtype=float)\n",
        "\n",
        "#Read the noisy signal\n",
        "with open('ECGsignal_n2700.csv') as csv_file:\n",
        "  csv_reader = csv.reader(csv_file)\n",
        "\n",
        "  for ECGsignal_n in csv_reader:\n",
        "    print(ECGsignal_n)\n",
        "  print(\"Finished reading the file\")\n",
        "\n",
        "#Time to dissect the file read data's anatomy:\n",
        "#Total number of items in the list:\n",
        "len(ECGsignal_n)\n",
        "\n",
        "#Convert the list to an array \n",
        "ECGsignal_n_arr = np.array(ECGsignal_n,dtype=float)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2YBfWXfv5Ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27787ba-918d-4ca5-b8b8-db70743403cb"
      },
      "source": [
        "tupleofdimensions = ECGsignal_arr.shape\n",
        "num = tupleofdimensions[0]\n",
        "Training_test_Split = 0.95  # Modify this line to control the Test-Train split\n",
        "\n",
        "a=Training_test_Split*num;                                 \n",
        "XTrain=ECGsignal_n_arr[0:int(a)];                  \n",
        "YTrain=ECGsignal_arr[0:int(a)];\n",
        "XTest=ECGsignal_n_arr[int(a):num];               \n",
        "YTest=ECGsignal_arr[int(a):num];\n",
        "scaling_factor = num/(5400000)\n",
        "train_samples=(30*60*Training_test_Split/10)*scaling_factor;\n",
        "test_samples =(30*60*(1-Training_test_Split)/10)*scaling_factor;\n",
        "\n",
        "print(XTrain.shape)\n",
        "print(XTest.shape)\n",
        "print(int(train_samples))\n",
        "print(int(test_samples))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25650000,)\n",
            "(1350000,)\n",
            "855\n",
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5Kbn3vsRXFX",
        "outputId": "dbe5b697-e735-47e9-bbe5-7ed5a3c2e1b9"
      },
      "source": [
        "print(YTrain.shape)\n",
        "print(YTest.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25650000,)\n",
            "(1350000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94xeGV8y1Gyg"
      },
      "source": [
        "Break up the Train and Test data into 4D vectors for the Tensorflow CNN: Format is [Batch_size,Height,width,depth]\n",
        "\n",
        "Reference:https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQwVYV0r1UYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca298e45-d1d8-45cc-a2b6-c221c5f6ccaa"
      },
      "source": [
        "XTrain_reshaped = np.reshape(XTrain,(int(train_samples),30000,1,1))\n",
        "YTrain_reshaped = np.reshape(YTrain,(int(train_samples),30000))\n",
        "\n",
        "XTest_reshaped = np.reshape(XTest,(int(test_samples),30000,1,1))\n",
        "YTest_reshaped = np.reshape(YTest,(int(test_samples),30000))\n",
        "\n",
        "print(XTest_reshaped.shape)\n",
        "print(XTrain_reshaped.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45, 30000, 1, 1)\n",
            "(855, 30000, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DS4G6DNdkC3"
      },
      "source": [
        "Start defining the layers of the CNN - From the De-noising paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppaaL62fdjsJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "893b83c1-93bd-410f-b10d-fddea80b5321"
      },
      "source": [
        "model = Sequential(name=\"DNN_using_CNN_for_Denoising\")\n",
        "\n",
        "# Convolution layers are used to extract the most prominent features of the input data.\n",
        "#Layer 1:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36, (19,1), input_shape=(30000,1,1),activation='relu',padding='SAME',strides=(1,1),name='conv_1')) \n",
        "model.add(BatchNormalization(name='batchnorm_1'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_1'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_1'))\n",
        "\n",
        "#Layer 2:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36,(19,1),strides=(1,1),padding='SAME',name='conv_2'))\n",
        "model.add(BatchNormalization(name='batchnorm_2'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_2'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_2'))\n",
        "\n",
        "#Layer 3:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36,(19,1),strides=(1,1),padding='SAME',name='conv_3'))\n",
        "model.add(BatchNormalization(name='batchnorm_3'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_3'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_3'))\n",
        "\n",
        "#Layer 4:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36,(19,1),strides=(1,1),padding='SAME',name='conv_4'))\n",
        "model.add(BatchNormalization(name='batchnorm_4'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_4'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_4'))\n",
        "\n",
        "\n",
        "#Layer 5:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36,(19,1),strides=(1,1),padding='SAME',name='conv_5'))\n",
        "model.add(BatchNormalization(name='batchnorm_5'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_5'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_5'))\n",
        "\n",
        "\n",
        "#Layer 6:\n",
        "#Conv-layer -> BatchNorm -> RELU-> AvdPooling\n",
        "model.add(Conv2D(36,(19,1),strides=(1,1),padding='SAME',name='conv_6'))\n",
        "model.add(BatchNormalization(name='batchnorm_6'))\n",
        "model.add(Dense(units=36,activation='relu',name='relu_6'))\n",
        "model.add(AveragePooling2D(pool_size=(2,1),strides=(4,1),name='avgpool_6'))\n",
        "model.add(Flatten())\n",
        "\n",
        "#Now adding in the fully-connected dense layer: This will act on the data extracted from the CNN in the prior stages\n",
        "model.add(Dense(units= 30000,activation=None,use_bias=True))\n",
        "model.summary()\n",
        "\n",
        "#Last layer of the FCN is only showing the inputsx weight.  \n",
        "#Investigating to see, if the bias is used. even though model summary is not displaying it.\n",
        "#weights, biases = model.layers[25].get_weights()\n",
        "#print(len(weights))\n",
        "#print(len(biases))\n",
        "\n",
        "#Build the model, we follow the paper, using Adam optimizer, for speeding up gradient descent\n",
        "#And RMS as the cost function, metric to optimize against.\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])\n",
        "\n",
        "#Fit the model.\n",
        "# Train the Model\n",
        "#history = model.fit_generator(train_generator,validation_data = validation_generator, epochs = 10,steps_per_epoch = 1372, validation_steps = 350,verbose = 1 )\n",
        "history = model.fit(XTrain_reshaped,YTrain_reshaped,epochs=10,verbose=2,validation_data=(XTest_reshaped,YTest_reshaped))\n",
        "\n",
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "mse = history.history['mse']\n",
        "val_mse = history.history['val_mse']\n",
        "\n",
        "\n",
        "epochs = range(len(mse))\n",
        "\n",
        "plt.plot(epochs, mse, 'r', label='MSE')\n",
        "plt.plot(epochs, val_mse, 'b', label='Validation MSE')\n",
        "plt.title('Training and validation MSE')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.show()\n",
        "                                    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"DNN_using_CNN_for_Denoising\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 30000, 1, 36)      720       \n",
            "_________________________________________________________________\n",
            "batchnorm_1 (BatchNormalizat (None, 30000, 1, 36)      144       \n",
            "_________________________________________________________________\n",
            "relu_1 (Dense)               (None, 30000, 1, 36)      1332      \n",
            "_________________________________________________________________\n",
            "avgpool_1 (AveragePooling2D) (None, 7500, 1, 36)       0         \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 7500, 1, 36)       24660     \n",
            "_________________________________________________________________\n",
            "batchnorm_2 (BatchNormalizat (None, 7500, 1, 36)       144       \n",
            "_________________________________________________________________\n",
            "relu_2 (Dense)               (None, 7500, 1, 36)       1332      \n",
            "_________________________________________________________________\n",
            "avgpool_2 (AveragePooling2D) (None, 1875, 1, 36)       0         \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 1875, 1, 36)       24660     \n",
            "_________________________________________________________________\n",
            "batchnorm_3 (BatchNormalizat (None, 1875, 1, 36)       144       \n",
            "_________________________________________________________________\n",
            "relu_3 (Dense)               (None, 1875, 1, 36)       1332      \n",
            "_________________________________________________________________\n",
            "avgpool_3 (AveragePooling2D) (None, 469, 1, 36)        0         \n",
            "_________________________________________________________________\n",
            "conv_4 (Conv2D)              (None, 469, 1, 36)        24660     \n",
            "_________________________________________________________________\n",
            "batchnorm_4 (BatchNormalizat (None, 469, 1, 36)        144       \n",
            "_________________________________________________________________\n",
            "relu_4 (Dense)               (None, 469, 1, 36)        1332      \n",
            "_________________________________________________________________\n",
            "avgpool_4 (AveragePooling2D) (None, 117, 1, 36)        0         \n",
            "_________________________________________________________________\n",
            "conv_5 (Conv2D)              (None, 117, 1, 36)        24660     \n",
            "_________________________________________________________________\n",
            "batchnorm_5 (BatchNormalizat (None, 117, 1, 36)        144       \n",
            "_________________________________________________________________\n",
            "relu_5 (Dense)               (None, 117, 1, 36)        1332      \n",
            "_________________________________________________________________\n",
            "avgpool_5 (AveragePooling2D) (None, 29, 1, 36)         0         \n",
            "_________________________________________________________________\n",
            "conv_6 (Conv2D)              (None, 29, 1, 36)         24660     \n",
            "_________________________________________________________________\n",
            "batchnorm_6 (BatchNormalizat (None, 29, 1, 36)         144       \n",
            "_________________________________________________________________\n",
            "relu_6 (Dense)               (None, 29, 1, 36)         1332      \n",
            "_________________________________________________________________\n",
            "avgpool_6 (AveragePooling2D) (None, 7, 1, 36)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 252)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 30000)             7590000   \n",
            "=================================================================\n",
            "Total params: 7,722,876\n",
            "Trainable params: 7,722,444\n",
            "Non-trainable params: 432\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "27/27 - 117s - loss: 0.1593 - mse: 0.1593 - val_loss: 0.9765 - val_mse: 0.9765\n",
            "Epoch 2/10\n",
            "27/27 - 114s - loss: 0.1210 - mse: 0.1210 - val_loss: 0.5815 - val_mse: 0.5815\n",
            "Epoch 3/10\n",
            "27/27 - 114s - loss: 0.1162 - mse: 0.1162 - val_loss: 0.1597 - val_mse: 0.1597\n",
            "Epoch 4/10\n",
            "27/27 - 115s - loss: 0.1126 - mse: 0.1126 - val_loss: 0.1601 - val_mse: 0.1601\n",
            "Epoch 5/10\n",
            "27/27 - 112s - loss: 0.1060 - mse: 0.1060 - val_loss: 0.1452 - val_mse: 0.1452\n",
            "Epoch 6/10\n",
            "27/27 - 113s - loss: 0.0989 - mse: 0.0989 - val_loss: 0.1448 - val_mse: 0.1448\n",
            "Epoch 7/10\n",
            "27/27 - 114s - loss: 0.0927 - mse: 0.0927 - val_loss: 0.1329 - val_mse: 0.1329\n",
            "Epoch 8/10\n",
            "27/27 - 114s - loss: 0.0885 - mse: 0.0885 - val_loss: 0.1608 - val_mse: 0.1608\n",
            "Epoch 9/10\n",
            "27/27 - 112s - loss: 0.0832 - mse: 0.0832 - val_loss: 0.1384 - val_mse: 0.1384\n",
            "Epoch 10/10\n",
            "27/27 - 113s - loss: 0.0790 - mse: 0.0790 - val_loss: 0.1284 - val_mse: 0.1284\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctShmsIAebCZ"
      },
      "source": [
        "CHARTS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5EJxHiqehZ7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOt07WKtDirw"
      },
      "source": [
        "Start defining the LSTM implementation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VaLOkLGxoJ1"
      },
      "source": [
        "RE-shape the Data so that it can be used in the LSTM:  \n",
        "LSTM Input = [Sample,TimeSteps,Features]\n",
        "In out case it is: [Test/Training samples, 30000,1]\n",
        "\n",
        "Reference:\n",
        "https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2rC2nZWxr0x",
        "outputId": "61dbd7d2-0ca5-460e-ea07-4f0077287cc0"
      },
      "source": [
        "XTrain_reshaped = XTrain.reshape(int(train_samples),30000,1)\n",
        "YTrain_reshaped = YTrain.reshape(int(train_samples),30000,1)\n",
        "\n",
        "XTest_reshaped = XTest.reshape(int(test_samples),30000,1)\n",
        "YTest_reshaped = YTest.reshape(int(test_samples),30000,1)\n",
        "\n",
        "#print the input data shapes:\n",
        "print(\"Training data shapes: Input and Output\")\n",
        "print(XTrain_reshaped.shape)\n",
        "print(YTrain_reshaped.shape)\n",
        "\n",
        "print(\"Test data shapes: Input and Output\")\n",
        "print(XTest_reshaped.shape)\n",
        "print(YTest_reshaped.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shapes: Input and Output\n",
            "(171, 30000, 1)\n",
            "(171, 30000, 1)\n",
            "Test data shapes: Input and Output\n",
            "(9, 30000, 1)\n",
            "(9, 30000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVs4JvKHxkMo"
      },
      "source": [
        "The definition of the LSTM model follows below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe2pXI_YDnc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55e600b-5c67-4103-f35f-d23a13adb4a5"
      },
      "source": [
        "model1 = Sequential(name=\"DNN_using_LSTM_for_Denoising\");\n",
        "#The LSTM->RELU-> return sequential ouput.\n",
        "#model1.add(CuDNNLSTM(140,input_shape=(30000,1),name=\"lstm_1_relu_1\",return_sequences=True)) \n",
        "model1.add(LSTM(140,input_shape=(30000,1),name=\"lstm_1_relu_1\",activation='relu',return_sequences=True)) \n",
        "# sequential output/input -> LSTM2->Relu -> flattened output (return_sequence = false, by default)\n",
        "#The output of LSTM2 is a flattened output -> Fully connected layer.\n",
        "#model1.add(CuDNNLSTM(140,name=\"lstm_2_relu_2\"))\n",
        "model1.add(LSTM(140,name=\"lstm_2_relu_2\",activation='relu'))\n",
        "#Add the fully connected layer of 30000 \n",
        "model1.add(Dense(30000,activation=None))\n",
        "model1.summary()\n",
        "\n",
        "#Build the model, we follow the paper, using Adam optimizer, for speeding up gradient descent\n",
        "#And RMS as the cost function, metric to optimize against.\n",
        "optimizer = keras.optimizers.Adam(lr=0.01)\n",
        "#Compile the model\n",
        "model1.compile(optimizer=optimizer,loss='mean_squared_error',metrics=['mse','loss'])\n",
        "\n",
        "#Fit the model.\n",
        "# Train the Model\n",
        "history = model1.fit(XTrain_reshaped,YTrain_reshaped,epochs=1,validation_data=(XTest_reshaped,YTest_reshaped),verbose=1)\n",
        "\n",
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['mse']\n",
        "val_acc = history.history['val_mse']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1_relu_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2_relu_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"DNN_using_LSTM_for_Denoising\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1_relu_1 (LSTM)         (None, 30000, 140)        79520     \n",
            "_________________________________________________________________\n",
            "lstm_2_relu_2 (LSTM)         (None, 140)               157360    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30000)             4230000   \n",
            "=================================================================\n",
            "Total params: 4,466,880\n",
            "Trainable params: 4,466,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmjWCEyTgRgC"
      },
      "source": [
        "Helpful references:\n",
        "\n",
        "1)This explains why last dense layer has no activation function:\n",
        "  - we primarily do that if we are trying to accuractely do regression.\n",
        "\n",
        "https://stats.stackexchange.com/questions/361066/what-is-the-point-of-having-a-dense-layer-in-a-neural-network-with-no-activation\n",
        "\n",
        "2)This video shows how to implement a stacked LSTM model:\n",
        "https://www.youtube.com/watch?v=BSpXCRTOLJA\n",
        "\n",
        "3) This video shows the inner anatomy of an LSTM, primarily the sigmoid and Tanh, used for gating inside the LSTM:\n",
        "https://www.youtube.com/watch?v=8HyCNIVRbSU&t=632s\n",
        "\n",
        "4) The blogpost that references the video in 3. Is linked here:\n",
        "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
        "\n",
        "5) This is the link from Andrew NG, I studied to understand, why we use BatchNormalization in the CNN:\n",
        "https://www.youtube.com/watch?v=nUUqwaxLnWs\n",
        "\n",
        "6) Running on CPU vs GPU vs TPU???\n",
        "https://serverguy.com/comparison/cpu-vs-gpu-vs-tpu/\n",
        "\n",
        "\n"
      ]
    }
  ]
}